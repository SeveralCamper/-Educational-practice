# Educational-practice

## Задание по учебной практике для студентов очной формы обучения направления «Информатика и вычислительная техника» профиль «Программное обеспечение средств вычислительной техники и автоматизированных систем»

## Описание алгоритмов
### Стандарт Python: Python 3.10.4
### Используемые библиотеки и модули:
* CSV (comma-separated value) - это формат представления табличных данных (например, это могут быть данные из таблицы или данные из БД).
В стандартной библиотеке Python есть модуль csv, который позволяет работать с файлами в CSV формате.
import csv

* Requests - библиотека, позволяющая отправлять запросы HTTP в Python и получать ответы, соответственно.
import requests

* Requests.exceptions - расширение для библиотеки Requests, которое необходимо для отлавливания исключений ответов с запроса, таких как:
ConnectionError - ошибка соединения,  Timeout - превышено ожидание ответа, TooManyRedirects - слишком много перенаправлений.
from requests.exceptions import ConnectionError, Timeout, TooManyRedirects

* BeautifulSoup - это пакет Python для анализа документов HTML и XML. Он создает дерево синтаксического анализа для проанализированных страниц, которое можно использовать для извлечения данных из HTML, что полезно для парсинга веб-страниц.
from bs4 import BeautifulSoup

### Используемые функции:
* def fill_struct_list(): - функция; создает двумерный массив, который содержит в себе структуры, сформированные с помощью csv.reader по разделителю ';' из исходной таблицы. Затем форматирует информацию в удобный для работы и чтения вид.
Возвращаемое значение: массив структур tmp_struct_list.
* def print_table(struct_list): - процедурная функция; создает структуру с помощью конструктора PrettyTable(), а затем построчно добавляет информацию в данную структуру по заранее заданным нами полям "Name", "Market_cap", "Price". Выводит всю информацию в виде приятной для глаза таблицы.
* def search_table(struct_list): - функция; функция поиска по ключу в переданной структуре. Находит по ключу необходимое поле и создает новую структуру, в которую будут переданы все строки таблицы с необходимыми данными.
Возвращаемое значение: массив структур fined_elements_arr.
* def parse_site(): - функция; создает header, который был в ручную добавлен  при первом вхождении мной на сайт: User-Agent. Он необходим для того, чтобы в последующих запросах алгоритма на сайт, сам сайт расценивал нас как пользователя, а не скрипт. Таким образом, мы сможем отправлять запросы без риска быть заблокированы защитой сайта. После этого, была считана вся информация с сайта и попутно переведена в lxml формат с помощью пакета анализа документов BeautifulSoup. Затем выделена необходимая информация по тегу "tbody", а далее найдена вся информация по тегам "p", "span" и "div", для нахождения параметров таблицы Name, Market_cap и Price, соответственно. Далее вся информация занесена по прошлому методу в массив структур с данными.
Возвращаемое значение: массив структур tmp_struct_list.

* main(): - интерфейс пользователя и разделение на задачи для считывания с файла и с сайта.
